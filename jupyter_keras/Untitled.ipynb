{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is one of the speeches by Barack Obama:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.utils.data_utils import get_file\n",
    "path = get_file('speech.json', origin='https://github.com/Vocativ-data/presidents_readability/raw/master/The%20original%20speeches.json')\n",
    "with open(path) as fp:\n",
    "   raw_data = json.load(fp)\n",
    "\n",
    "print(\"This is one of the speeches by {}:\".format(raw_data['objects'][0]['President']))\n",
    "#print(raw_data['objects'][0]['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "nlp = English(parser=True)\n",
    "### nlp is a callable object---it implements most of spacy's API\n",
    "data1 = nlp(raw_data['objects'][0]['Text'])\n",
    "data2 = map(list, data1.sents)\n",
    "print (data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print (len(raw_data['objects']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 9 7 8 4 0 6 2 5]\n",
      "623\n",
      "(7, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def process_raw_data(raw_data):\n",
    "    flat_raw = [datum['Text'] for datum in raw_data['objects']]\n",
    "    nb_data = 10### we are only going to a test dataset len(flat_raw)\n",
    "    all_indices = np.random.choice(np.arange(nb_data), nb_data, replace=False)\n",
    "    train_portion, dev_portion = 0.7, 0.2\n",
    "    num_train, num_dev = int(train_portion*nb_data), int(dev_portion*nb_data)\n",
    "    train_indices = all_indices[:num_train]\n",
    "    dev_indices = all_indices[num_train:num_train+num_dev]\n",
    "    test_indices = all_indices[num_train+num_dev:]\n",
    "    \n",
    "    nlp = English(parser=True)\n",
    "    raw_train_data = [nlp(flat_raw[i]).sents for i in train_indices]\n",
    "    raw_train_data = [[str(word).strip() for word in sentence] for speech in raw_train_data for sentence in speech]\n",
    "    raw_dev_data = [nlp(flat_raw[i]).sents for i in dev_indices]\n",
    "    \n",
    "    a = raw_train_data[0]\n",
    "    print (type(a))\n",
    "\n",
    "    \n",
    "process_raw_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
