{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_shape, output_shape, reinstantiate model\n",
    "Dense, LSTM, Embedding layers, Convoluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, Convolution1D\n",
    "from keras.layers import Embedding, LSTM, SimpleRNN, TimeDistributed\n",
    "from keras.layers import MaxPooling2D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((None, 784), (None, 20))\n",
      "((None, 784), (None, 20))\n",
      "(100, 20)\n",
      "(22, 20)\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential([Dense(output_dim = 20, input_shape = (784, ))\n",
    "                     ])\n",
    "model_2 = Sequential([Dense(output_dim = 20, input_dim = 784)\n",
    "                     ])\n",
    "\n",
    "x = np.random.uniform(size=(22, 784))\n",
    "# Dense layer: \n",
    "##  input_shape  (nb_samples, input_dim)\n",
    "##  output_shape (nb_samples, output_dim)\n",
    "print (model_1.input_shape, model_1.output_shape)\n",
    "print (model_2.input_shape, model_2.output_shape)\n",
    "print model_1.layers[0].get_output_shape_for((100, 784))\n",
    "output = model_1.predict(x)\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((None, None), (None, None, 150))\n",
      "(100, 3, 150)\n"
     ]
    }
   ],
   "source": [
    "word_vec_dim = 150\n",
    "voca_size = 2000\n",
    "n_samples = 100\n",
    "seq_length = 3\n",
    "model_1 = Sequential([Embedding(output_dim = word_vec_dim, input_dim = voca_size)])\n",
    "# Embedding layer:\n",
    "## input_shape  (nb_samples, sequence_length)\n",
    "## output_shape (nb_samples, sequence_length, output_dim)\n",
    "print (model_1.layers[0].input_shape, model_1.layers[0].output_shape)\n",
    "x = np.random.randint(low=0, high=2000, size=(n_samples, seq_length))\n",
    "output = model_1.predict(x)\n",
    "print (output.shape) # (n_samples, seq_length, word_vec_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((None, 10, 50), (None, 10, 150))\n"
     ]
    }
   ],
   "source": [
    "input_dim = 50\n",
    "output_dim = 150\n",
    "seq_length = 10\n",
    "model = Sequential()\n",
    "#model.add(SimpleRNN(output_dim=output_dim, input_dim=input_dim, input_length=seq_length, return_sequences=True))\n",
    "model.add(SimpleRNN(output_dim=output_dim, input_shape=(seq_length, input_dim), return_sequences=True))\n",
    "# SimpleRNN\n",
    "## input_shape  (nb_samples, timesteps, input_dim)\n",
    "## output_shape (nb_samples, timesteps, output_dim)\n",
    "print (model.input_shape, model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 150)\n",
      "(None, 300)\n",
      "(20, 300)\n",
      "(20, 10, 300)\n"
     ]
    }
   ],
   "source": [
    "input_dim = 150\n",
    "hidden_dim = 300\n",
    "seq_length = 10\n",
    "n_samples = 20\n",
    "\n",
    "model_1 = Sequential([LSTM(output_dim = hidden_dim, input_dim = input_dim, input_length = seq_length)])\n",
    "# LSTM layer\n",
    "## input_shape  (nb_samples, timesteps, input_dim)\n",
    "## output_shape: \n",
    "####          return_sequences==True: (nb_samples, timesteps, input_dim) \n",
    "####          return_sequences==False: (nb_samples, input_dim) ### only the last output returned\n",
    "print (model_1.layers[0].input_shape)\n",
    "print (model_1.layers[0].output_shape)\n",
    "x = np.random.uniform(size=(n_samples, seq_length, input_dim))\n",
    "output = model_1.predict(x)\n",
    "print (output.shape)\n",
    "\n",
    "model_2 = Sequential([LSTM(output_dim = hidden_dim, input_dim = input_dim, input_length = seq_length, \n",
    "                           return_sequences=True)]) ## return sequences\n",
    "output = model_2.predict(x)\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrapper: TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((None, 10), (None, 10, 200))\n"
     ]
    }
   ],
   "source": [
    "voca_size = 1000\n",
    "seq_length = 10\n",
    "word_vec_dim = 100\n",
    "hidden_dim = 300\n",
    "output_dim = 200\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=word_vec_dim, input_dim=voca_size, input_length=seq_length))\n",
    "model.add(SimpleRNN(output_dim=hidden_dim, activation='sigmoid', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(output_dim=output_dim, activation='softmax')))\n",
    "print (model.input_shape, model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (None, 3, 256, 256)\n",
      "output_shape: (1, 1, 128, 64)\n",
      "conv layer: weight_shape: (5, 5, 256, 64), bias_shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "nb_filter = 64\n",
    "rf_size = (5, 5) # receptive field size\n",
    "input_shape = (3, 256, 256) # 256x256 RGB picture\n",
    "strides = (2, 2)\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filter=nb_filter, nb_row=rf_size[0], nb_col=rf_size[1], input_shape=input_shape, \n",
    "                                 border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Convolution2D layer\n",
    "## dim_ordering == 'th'\n",
    "####   input_shape  (nb_samples, channels, rows, cols)\n",
    "####   output_shape (nb_samples, nb_filter, new_rows, new_cols)\n",
    "\n",
    "## dim_ordering == 'tf'\n",
    "####   input_shape  (nb_samples, rows, cols, channels)\n",
    "####   output_shape (nb_samples, new_rows, new_cols, nb_filter)\n",
    "\n",
    "print ('input_shape: {0}'.format(model.layers[0].input_shape))\n",
    "x = np.random.uniform(size=(1, 3, 256, 256))\n",
    "\n",
    "output = model.predict(x)\n",
    "print ('output_shape: {0}'.format(output.shape))\n",
    "ws = model.layers[0].get_weights()\n",
    "print ('conv layer: weight_shape: {0}, bias_shape: {1}'.format(ws[0].shape, ws[1].shape)) # kernel shape (nb_filters, nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (None, None, 32)\n",
      "output_shape: (1, 8, 64)\n",
      "weight_shape: (3, 1, 32, 64), bias_shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "nb_filter = 64\n",
    "rf_size = 3\n",
    "input_dim = 32 ## channels to Convolution2D\n",
    "model = Sequential([Convolution1D(nb_filter=nb_filter, filter_length=rf_size, input_dim=32)])\n",
    "# Convolution1D\n",
    "## input_shape  (nb_samples, timesteps, channels)\n",
    "## output_shape (nb_samples, new_timesteps, nb_filter)\n",
    "print ('input_shape: {0}'.format(model.input_shape))\n",
    "x = np.random.uniform(size=(1, 10, input_dim))\n",
    "output = model.predict(x)\n",
    "print ('output_shape: {0}'.format(output.shape))\n",
    "ws = model.layers[0].get_weights()\n",
    "print ('weight_shape: {0}, bias_shape: {1}'.format(ws[0].shape, ws[1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## reinstantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, LSTM, Embedding, Merge\n",
    "from keras.models import Sequential, Model, model_from_yaml, model_from_json\n",
    "from jupyter_notebook.datasets.importer.mnist_importer import MnistImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test test sequential_10 sequential_11\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential(name='test')\n",
    "    model.add(Dense(output_dim=100, input_dim=784))\n",
    "    model.add(Dense(output_dim=10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def reinstantiate_model(model):\n",
    "    config = model.get_config()\n",
    "    config[0]['model_name'] = model.name\n",
    "    json = model.to_json()\n",
    "    yaml = model.to_yaml()\n",
    "    \n",
    "    model_config = Sequential.from_config(config)\n",
    "    model_config.name = config[0]['model_name']\n",
    "    model_json = model_from_json(json)\n",
    "    model_yaml = model_from_yaml(yaml)\n",
    "    \n",
    "    print model.name, model_config.name, model_json.name, model_yaml.name\n",
    "\n",
    "model = build_model()\n",
    "reinstantiate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Sequential\", \"keras_version\": \"1.2.2\", \"config\": [{\"class_name\": \"Dense\", \"config\": {\"W_constraint\": null, \"b_constraint\": null, \"name\": \"dense_3\", \"output_dim\": 100, \"activity_regularizer\": null, \"trainable\": true, \"init\": \"glorot_uniform\", \"bias\": true, \"input_dtype\": \"float32\", \"input_dim\": 784, \"b_regularizer\": null, \"W_regularizer\": null, \"activation\": \"linear\", \"batch_input_shape\": [null, 784]}}, {\"class_name\": \"Dense\", \"config\": {\"W_constraint\": null, \"b_constraint\": null, \"name\": \"dense_4\", \"activity_regularizer\": null, \"trainable\": true, \"init\": \"glorot_uniform\", \"bias\": true, \"input_dim\": 100, \"b_regularizer\": null, \"W_regularizer\": null, \"activation\": \"softmax\", \"output_dim\": 10}}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_str = model.to_json()\n",
    "config = json.loads(json_str)\n",
    "print json_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_input_14:0\", shape=(?, 784), dtype=float32)\n",
      "[<keras.layers.core.Dense object at 0x7f7eb8706910>, <keras.layers.core.Dense object at 0x7f7eb8706d10>]\n",
      "<keras.layers.core.Dense object at 0x7f7eb8706910>\n"
     ]
    }
   ],
   "source": [
    "def mlp_mnist():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_shape=(784, ), output_dim=64, name='hidden_1', activation='relu'))\n",
    "    model.add(Dense(output_dim=10, name='output', activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = mlp_mnist()\n",
    "input = model.input\n",
    "hidden_1 = model.get_layer('hidden_1')\n",
    "layers = model.layers\n",
    "print input\n",
    "print layers\n",
    "print hidden_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
