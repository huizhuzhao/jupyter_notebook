{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG net demo\n",
    "details refer to https://github.com/Microsoft/CNTK/blob/v2.0.beta3.0/bindings/python/tutorials/CNTK_201B_CIFAR-10_ImageHandsOn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'momentum_as_time_constant_schedule'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0589cb5f166f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcntk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglorot_uniform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhe_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcntk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcntk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmomentum_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum_as_time_constant_schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcntk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcntk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_entropy_with_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'momentum_as_time_constant_schedule'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from cntk.blocks import default_options\n",
    "from cntk.layers import Convolution, MaxPooling, AveragePooling, Dropout, BatchNormalization, Dense\n",
    "from cntk.models import Sequential, LayerStack\n",
    "from cntk.io import MinibatchSource, ImageDeserializer, StreamDef, StreamDefs\n",
    "from cntk.initializer import glorot_uniform, he_normal\n",
    "from cntk import Trainer\n",
    "from cntk.learner import momentum_sgd, learning_rate_schedule, momentum_as_time_constant_schedule\n",
    "import cntk.ops as C\n",
    "from cntk.ops import cross_entropy_with_softmax, classification_error, relu, input_variable, softmax, element_times\n",
    "from cntk.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model dimensions\n",
    "image_height = 32\n",
    "image_width  = 32\n",
    "num_channels = 3\n",
    "num_classes  = 10\n",
    "def create_reader(map_file, mean_file, train):\n",
    "    if not os.path.exists(map_file) or not os.path.exists(mean_file):\n",
    "        raise RuntimeError(\"This tutorials depends 201A tutorials, please run 201A first.\")\n",
    "\n",
    "    # transformation pipeline for the features has jitter/crop only when training\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms += [\n",
    "            ImageDeserializer.crop(crop_type='Random', ratio=0.8, jitter_type='uniRatio') # train uses jitter\n",
    "        ]\n",
    "    transforms += [\n",
    "        ImageDeserializer.scale(width=image_width, height=image_height, channels=num_channels, interpolations='linear'),\n",
    "        ImageDeserializer.mean(mean_file)\n",
    "    ]\n",
    "    # deserializer\n",
    "    return MinibatchSource(ImageDeserializer(map_file, StreamDefs(\n",
    "        features = StreamDef(field='image', transforms=transforms), # first column in map file is referred to as 'image'\n",
    "        labels   = StreamDef(field='label', shape=num_classes)      # and second as 'label'\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/xtalpi/git_test/test_data/examples/cifar-10/cntk/'\n",
    "train_map = data_dir + 'train_map.txt'\n",
    "test_map = data_dir + 'test_map.txt'\n",
    "mean_xml = data_dir + 'CIFAR-10_mean.xml'\n",
    "reader_train = create_reader(train_map, mean_xml, True)\n",
    "reader_test = create_reader(test_map, mean_xml, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(input, out_dims):\n",
    "    net = Convolution(filter_shape=(5, 5), num_filters=32, activation=C.relu, init=glorot_uniform(), pad=True)(input)\n",
    "    net = MaxPooling(filter_shape=(3, 3), strides=(2, 2))(net)\n",
    "    \n",
    "    net = Convolution(filter_shape=(5, 5), num_filters=32, activation=C.relu, init=glorot_uniform(), pad=True)(net)\n",
    "    net = MaxPooling(filter_shape=(3, 3), strides=(2, 2))(net)\n",
    "    \n",
    "    net = Convolution(filter_shape=(5, 5), num_filters=64, activation=C.relu, init=glorot_uniform(), pad=True)(net)\n",
    "    net = MaxPooling(filter_shape=(3, 3), strides=(2, 2))(net)\n",
    "    \n",
    "    net = Dense(64, init=glorot_uniform())(net)\n",
    "    net = Dense(out_dims, init=glorot_uniform(), activation=None)(net)\n",
    "    \n",
    "    return net\n",
    "\n",
    "def train_and_evaluate(reader_train, reader_test, max_epochs, model_func):\n",
    "    # Input variables denoting the features and label data\n",
    "    input_var = input_variable((num_channels, image_height, image_width))\n",
    "    label_var = input_variable((num_classes))\n",
    "    feature_scale = 1.0 / 256.0\n",
    "    input_var_norm = element_times(input_var, feature_scale)\n",
    "    \n",
    "    net = create_model(input_var_norm, num_classes)\n",
    "    \n",
    "    cross_entropy = C.cross_entropy_with_softmax(net, label_var)\n",
    "    error = C.classification_error(net, label_var)\n",
    "    \n",
    "    epoch_size     = 50000\n",
    "    minibatch_size = 64\n",
    "\n",
    "    # Set training parameters\n",
    "    lr_per_minibatch       = learning_rate_schedule([0.01]*10 + [0.003]*10 + [0.001], epoch_size)\n",
    "    momentum_time_constant = momentum_as_time_constant_schedule(-minibatch_size/np.log(0.9))\n",
    "    l2_reg_weight          = 0.001\n",
    "    print (lr_per_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'momentum_as_time_constant_schedule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-535fb5123ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-139412a7bdbe>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(reader_train, reader_test, max_epochs, model_func)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Set training parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mlr_per_minibatch\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmomentum_time_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmomentum_as_time_constant_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0ml2_reg_weight\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlr_per_minibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'momentum_as_time_constant_schedule' is not defined"
     ]
    }
   ],
   "source": [
    "#train_and_evaluate(reader_train, reader_test, 100, create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 480, 640)\n",
      "(1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "input_var = input_variable((3, 480, 640))\n",
    "net = create_model(input_var, 10)\n",
    "img_mat = np.asarray(np.random.uniform(size=(3, 480, 640)), dtype=np.float32)\n",
    "y = net.eval({input_var: img_mat})\n",
    "print (img_mat.shape)\n",
    "print (y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = C.input_variable(100, np.float32)\n",
    "layer_1 = Dense(10, activation=C.relu)(input)\n",
    "layer_2 = Dense(10, activation=None)(input)\n",
    "layer_3 = Dense(10)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cntk.ops.variables.Parameter; proxy of <Swig Object of type 'CNTK::Parameter *' at 0x7f939594d180> >\n",
      "[[[ 0.          0.          0.          0.61932898  0.          0.          0.\n",
      "    0.          0.          0.43507668]]]\n",
      "[[[ 0.24702844 -0.89035076  0.54310364 -0.3095201   0.06112466  0.29654005\n",
      "   -0.91910577  0.61358446  0.05095169 -0.10280191]]]\n",
      "[[[ 0.64680076  0.51406795 -0.47399288 -0.79891557 -0.04575209  0.33376914\n",
      "    0.0175259  -0.3553077   0.52166581  0.33447912]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(size=(100)).astype(np.float32)\n",
    "para = C.parameter(shape=(list(input.shape)+[10]), init=glorot_uniform())\n",
    "print (para)\n",
    "y_1 = layer_1.eval({input: x})\n",
    "y_2 = layer_2.eval({input: x})\n",
    "y_3 = layer_3.eval({input: x})\n",
    "print (y_1)\n",
    "print (y_2)\n",
    "print (y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cntk-py34]",
   "language": "python",
   "name": "conda-env-cntk-py34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
